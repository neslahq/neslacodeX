model:
  n_embd: 768
  n_head: 12
  n_layers: 12
  n_exp: 5 
  p: 2
  top_k: 4
  capacity_factor: 1.25
  use_router_noise: true
  bias: true
  use_moe: false
  block_size: 1024
  vocab_size: 50304
  dropout: 0.1
  use_router_z_loss: true
  use_aux_loss: true
  aux_loss_weight: 0.01
  router_z_loss_weight: 0.001
  matmul_precision: high
  optimizer:
    name: AdamW
    learning_rate: 6e-4
    weight_decay: 0.1
    max_lr: 6e-4
    min_lr: 6e-5
    warmup_steps: 10

data:
  path: 

train:
  epochs: 1
  max_steps: 50
  total_batch_size: 524288 
  ddp: false
  gradient_accumulation: false
  num_warmups: 1