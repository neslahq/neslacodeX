model:
  n_embd: 768
  n_head: 12
  n_layers: 12
  seq_len: 1024
  n_exp: 5 
  p: 2
  top_k: 4
  capacity_factor: 1.25
  use_router_noise: true
  bias: true
  use_moe: false
  block_size: 1024
  vocab_size: 50304
  dropout: 0.1
  use_router_z_loss: true
  use_aux_loss: true
  aux_loss_weight: 0.01
  router_z_loss_weight: 0.001
  matmul_precision: highest
  use_flex_attn: false
  optimizer:
    name: AdamW
    learning_rate: 6e-4
    weight_decay: 0.1
    max_lr: 6e-4
    min_lr: 6e-5
    warmup_steps: 10
  compile:
    enable: false

data:
  path: ''

train:
  epochs: 1
  max_steps: 10
  total_batch_size: 524288 
  ddp: false
  gradient_accumulation: false
  num_warmups: 0
  autocast: false
  enable_backward: true
  benchmark_output_path: ''
  export_benchmark: true
  enable_cpu_offload: false
  activation_checkpoint:
    mode: "none"
  mixed_precision_param: "bfloat16"
  mixed_precision_reduce: "bfloat16"

parallelism:
  pipeline_parallel_schedule: "1F1B"
  pipeline_parallel_layers_per_stage: None
  pipeline_parallel_first_stage_less_layers: 1
  pipeline_parallel_last_stage_less_layers: 1
  context_parallel_degree: 1
  disable_loss_parallel: false
  enable_compiled_autograd: false
  

